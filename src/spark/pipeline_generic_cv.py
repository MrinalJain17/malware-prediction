import sys

from pyspark.sql import SparkSession

from pyspark.ml import Pipeline
from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator, VectorAssembler, Normalizer
from pyspark.ml.classification import DecisionTreeClassifier, LogisticRegression, GBTClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.ml.tuning import CrossValidator, ParamGridBuilder

HOME_DIR = 'hdfs://dumbo/user/ns4486/'
PIPELINE_DIR = HOME_DIR + 'pipelines/'
WRITE_DIR = HOME_DIR + 'write/'
READ_DIR = HOME_DIR + 'datasets/'
CV_DIR = HOME_DIR + 'cross_validators/'

model = sys.argv[0]
spark = SparkSession.builder.getOrCreate()

train_df = spark.read.load(WRITE_DIR +'train_clean.parquet', format = "parquet", inferSchema = "true", header = "true")

if (model == 'lr') {
    learningModel = LogisticRegression(
        featuresCol = 'normFeatures',
        labelCol = 'HasDetections'
    )

    paramGrid = ParamGridBuilder() \
        .addGrid(learningModel.threshold, [0.3, 0.4, 0.5, 0.6]) \
        .build()

} else if (model == 'gbt') {
    learningModel = GBTClassifier(
        featuresCol = 'normFeatures',
        labelCol = 'HasDetections'
    )

    paramGrid = ParamGridBuilder() \
        .addGrid(learningModel.maxIter, [3, 4, 5]) \
        .addGrid(learningModel.maxDept, [4, 5, 6]) \
        .build()
        
} else if (model == 'rf') {
    learningModel = DecisionTreeClassifier(
        featuresCol = 'normFeatures',
        labelCol = 'HasDetections'
    )

    paramGrid = ParamGridBuilder() \
        .addGrid(learningModel.numTrees, [3, 4, 5]) \
        .build()
}



pipelineStages = []
pipelineStages += [learningModel]
pipeline = Pipeline(stages = pipelineStages)

evaluator = MulticlassClassificationEvaluator(
    labelCol = 'HasDetections',
    predictionCol = 'prediction',
    metricName = 'accuracy'
)

crossval = CrossValidator(
    estimator = pipeline,
    estimatorParamMaps = paramGrid,
    evaluator = evaluator,
    numFolds = 3
)

train_df = spark.createDataFrame(train_df.rdd, schema = train_df.schema)

cvModel = crossval.fit(train_df)

cvModel.save(CV_DIR + 'cv_' + model)

# predictions = cvModel.transform(test_df)

# accuracy = evaluator.evaluate(predictions)

# print('[RESULTS] accuracy = ' + accuracy)